---
title: بینائی، زبان، اور عمل (Vision Language Action)
sidebar_position: 5
---

## وژن-لینگویج-ایکشن (VLA): LLMs اور روبوٹکس کا امتزاج

یہ ماڈیول **وژن-لینگویج-ایکشن (VLA)** ماڈلز کے دلچسپ شعبے کو تلاش کرتا ہے، جہاں ہم انسانی زبان اور روبوٹک عمل کے درمیان فاصلے کو پر کرتے ہیں۔

### آواز سے عمل تک

ہم اپنے روبوٹ کو صوتی کمانڈز سمجھنے کے قابل بنانے کے لیے **OpenAI Whisper** استعمال کریں گے۔ یہ ایک قدرتی اور بدیہی انسانی-روبوٹ انٹرفیس بنانے کا پہلا قدم ہے۔

### LLMs کے ساتھ کاگنیٹو پلاننگ

VLA کی حقیقی طاقت کاگنیٹو پلاننگ کے لیے **Large Language Models (LLMs)** کے استعمال سے حاصل ہوتی ہے۔ آپ سیکھیں گے کہ اعلیٰ سطحی قدرتی زبان کی کمانڈز، جیسے "کمرہ صاف کریں،" کو ROS 2 کے قابل عمل اعمال کی ترتیب میں کیسے ترجمہ کیا جائے۔

### کیپ سٹون پروجیکٹ: خود مختار ہیومنائیڈ

یہ ماڈیول ایک کیپ سٹون پروجیکٹ پر اختتام پذیر ہوگا جہاں آپ سمولیشن میں ایک خود مختار ہیومنائیڈ روبوٹ بنائیں گے۔ روبوٹ قابل ہوگا کہ:

1.  ایک صوتی کمانڈ وصول کرے۔
2.  ہدف کی جگہ تک راستہ کا منصوبہ بنائے۔
3.  ایک بے ترتیب ماحول میں نیویگیٹ کرے، رکاوٹوں سے بچتے ہوئے۔
4.  کمپیوٹر وژن کا استعمال کرتے ہوئے ہدف آبجیکٹ کی شناخت کرے۔
5.  آبجیکٹ کو ہیرا پھیری کرے۔

### ہفتہ 13: کنورزیشنل روبوٹکس

آخری ہفتے میں، ہم کنورزیشنل روبوٹکس پر توجہ مرکوز کریں گے:

-   **GPT انٹیگریشن:** اپنے روبوٹ کے لیے ایک کنورزیشنل AI بنانے کے لیے GPT ماڈلز کو انٹیگریٹ کریں۔
-   **اسپیچ اور لینگویج:** اسپیچ ریکگنیشن اور قدرتی زبان کی تفہیم میں گہرائی میں جائیں۔
-   **ملٹی ماڈل انٹریکشن:** تقریر، اشاروں اور وژن کو ایک بھرپور انٹرایکٹو تجربے کے لیے کیسے یکجا کیا جائے اس پر غور کریں۔

### اسیسمنٹس

-   ROS 2 پیکیج ڈویلپمنٹ پروجیکٹ
-   Gazebo سمولیشن امپلیمینٹیشن
-   Isaac پر مبنی پرسیپشن پائپ لائن
-   کیپ سٹون: کنورزیشنل AI کے ساتھ سمولیٹڈ ہیومنائیڈ روبوٹ